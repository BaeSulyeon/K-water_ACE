{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import StackingRegressor, ExtraTreesRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Data leakage is impossible\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata.xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\kwater\\lib\\site-packages\\pandas\\io\\excel\\_base.py:478\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    477\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 478\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    481\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    482\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    483\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\kwater\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1496\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1494\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1496\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m   1498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1499\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1501\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1502\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1503\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\kwater\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1371\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1369\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1371\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1372\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1373\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1374\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   1375\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\kwater\\lib\\site-packages\\pandas\\io\\common.py:868\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    869\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    871\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data.xlsx'"
     ]
    }
   ],
   "source": [
    "# Data leakage is impossible\n",
    "df=pd.read_excel('data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictive modeling of coagulants in medium turbidity communities.  \n",
    "def reg_clust_0():\n",
    "  df0=df[df['Cluster']==0]\n",
    "  df0=df0.reset_index(drop=True)\n",
    "  x=df0[['탁도','pH','수온','전기전도도','알칼리도']]\n",
    "  y=df0['PACS 투입률']\n",
    "  et_model = ExtraTreesRegressor(max_depth= 30,\n",
    "                               min_samples_leaf= 1,\n",
    "                               min_samples_split= 5,\n",
    "                               n_estimators=400, random_state=6666)\n",
    "  rf_model = RandomForestRegressor(max_depth= 30,\n",
    "                                 min_samples_leaf= 1,\n",
    "                                 min_samples_split= 2,\n",
    "                                 n_estimators=200, random_state=6666)\n",
    "  lgbm_model = lgb.LGBMRegressor(learning_rate= 0.1,\n",
    "                               max_depth= 20,\n",
    "                               min_child_samples= 10,\n",
    "                               n_estimators= 600,\n",
    "                               num_leaves= 62, random_state=6666,verbose=-1)\n",
    "  lr=LinearRegression()\n",
    "  estimators = [\n",
    "    ('rf', rf_model),\n",
    "    ('lgbm', lgbm_model),\n",
    "    ('extra', et_model),\n",
    "    ('lr', lr)\n",
    "  ]\n",
    "  stacking_regressor = StackingRegressor(\n",
    "      estimators=estimators,\n",
    "      final_estimator=lr)\n",
    "\n",
    "  model=stacking_regressor\n",
    "  model.fit(x,y)\n",
    "  joblib.dump(model, '../Docker_airflow_Kafka/models//reg_clust_0.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flocculant prediction modeling for low-turbidity, high-flocculant populations\n",
    "def reg_clust_1():\n",
    "  df1=df[df['Cluster']==1]\n",
    "  df1=df1.reset_index(drop=True)\n",
    "  x=df1[['탁도','pH','수온','전기전도도','알칼리도']]\n",
    "  y=df1['PACS 투입률']\n",
    "  et_model = ExtraTreesRegressor(max_depth=30,n_estimators=1000, random_state=6666)\n",
    "  lgbm_model = lgb.LGBMRegressor(max_depth=30,n_estimators=1000,learning_rate=0.1, random_state=6666,verbose=-1)\n",
    "  lr=LinearRegression()\n",
    "  estimators = [\n",
    "  ('lgbm', lgbm_model),\n",
    "  ('extra', et_model),\n",
    "  ('lr', lr)\n",
    "  ]\n",
    "  stacking_regressor = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=lr)\n",
    "  model=stacking_regressor\n",
    "  model.fit(x,y)\n",
    "  joblib.dump(model, '../Docker_airflow_Kafka/models//reg_clust_1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flocculant prediction modeling for low-turbidity, low-flocculant populations\n",
    "def reg_clust_2():\n",
    "  df2=df[df['Cluster']==2]\n",
    "  df2=df2.reset_index(drop=True)\n",
    "  x=df2[['탁도','pH','수온','전기전도도','알칼리도']]\n",
    "  y=df2['PACS 투입률']\n",
    "  et_model = ExtraTreesRegressor(max_depth= 20,\n",
    "                               min_samples_leaf= 1,\n",
    "                               min_samples_split= 5,\n",
    "                               n_estimators=300, random_state=6666)\n",
    "  rf_model = RandomForestRegressor(max_depth= 30,\n",
    "                                 min_samples_leaf= 1,\n",
    "                                 min_samples_split= 2,\n",
    "                                 n_estimators=500, random_state=6666)\n",
    "  lr=LinearRegression()\n",
    "  estimators = [\n",
    "    ('rf', rf_model),\n",
    "    ('extra', et_model),\n",
    "    ('lr',lr)\n",
    "  ]\n",
    "  stacking_regressor = StackingRegressor(\n",
    "      estimators=estimators,\n",
    "      final_estimator=lr)\n",
    "  model=stacking_regressor\n",
    "  model.fit(x,y)\n",
    "  joblib.dump(model, '../Docker_airflow_Kafka/models//reg_clust_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictive modeling of coagulants in high turbidity communities.\n",
    "def reg_clust_3():\n",
    "  df3=df[df['Cluster']==3]\n",
    "  df3=df3.reset_index(drop=True)\n",
    "  x=df3[['탁도','pH','수온','전기전도도','알칼리도']]\n",
    "  y=df3['PACS 투입률']\n",
    "  et_model = ExtraTreesRegressor(max_depth= None,\n",
    "                               min_samples_leaf= 1,\n",
    "                               min_samples_split= 2,\n",
    "                               n_estimators=150, random_state=6666)\n",
    "  rf_model = RandomForestRegressor(max_depth= None,\n",
    "                                 min_samples_leaf= 1,\n",
    "                                 min_samples_split= 2,\n",
    "                                 n_estimators=200, random_state=6666)\n",
    "  lgbm_model = lgb.LGBMRegressor(learning_rate= 0.1,\n",
    "                               max_depth= 20,\n",
    "                               min_child_samples= 10,\n",
    "                               n_estimators= 500,\n",
    "                               num_leaves= 80, random_state=6666,verbose=-1)\n",
    "  lr=LinearRegression()\n",
    "  estimators = [\n",
    "    ('rf', rf_model),\n",
    "    ('lgbm', lgbm_model),\n",
    "    ('extra', et_model),\n",
    "    ('lr',lr)\n",
    "  ]\n",
    "  \n",
    "  stacking_regressor = StackingRegressor(\n",
    "      estimators=estimators,\n",
    "      final_estimator=lr)\n",
    "  model=stacking_regressor\n",
    "  model.fit(x,y)\n",
    "  joblib.dump(model, '../Docker_airflow_Kafka/models/reg_clust_3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_clust_0()\n",
    "reg_clust_1()\n",
    "reg_clust_2()\n",
    "reg_clust_3()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_10_4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
